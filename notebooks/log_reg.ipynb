{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Packages, Functions, and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create a Model and Train It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement creates an instance of LogisticRegression and binds its references to the variable model. LogisticRegression has several optional parameters that define the behavior of the model and approach:\n",
    "\n",
    "* penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "* dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "\n",
    "* tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "* C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "* fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept ùëè‚ÇÄ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "* intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept ùëè‚ÇÄ.\n",
    "\n",
    "* class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "* random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "* solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "* max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "\n",
    "* multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n",
    "* verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "\n",
    "* warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "\n",
    "* n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "*  l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.04608067])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51491375]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74002157, 0.25997843],\n",
       "       [0.62975524, 0.37024476],\n",
       "       [0.5040632 , 0.4959368 ],\n",
       "       [0.37785549, 0.62214451],\n",
       "       [0.26628093, 0.73371907],\n",
       "       [0.17821501, 0.82178499],\n",
       "       [0.11472079, 0.88527921],\n",
       "       [0.07186982, 0.92813018],\n",
       "       [0.04422513, 0.95577487],\n",
       "       [0.02690569, 0.97309431]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix above, each row corresponds to a single observation. The first column is the probability of the predicted output being zero, that is 1 - ùëù(ùë•). The second column is the probability that the output is one, or ùëù(ùë•).\n",
    "\n",
    "You can get the actual predictions, based on the probability matrix and the values of ùëù(ùë•), with .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the Model\n",
    "\n",
    "You can improve your model by setting different parameters. For example, let‚Äôs work with the regularization strength C equal to 10.0, instead of the default value of 1.0:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.51335372])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12066084]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97106534, 0.02893466],\n",
       "       [0.9162684 , 0.0837316 ],\n",
       "       [0.7810904 , 0.2189096 ],\n",
       "       [0.53777071, 0.46222929],\n",
       "       [0.27502212, 0.72497788],\n",
       "       [0.11007743, 0.88992257],\n",
       "       [0.03876835, 0.96123165],\n",
       "       [0.01298011, 0.98701989],\n",
       "       [0.0042697 , 0.9957303 ],\n",
       "       [0.00139621, 0.99860379]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression in Python With scikit-learn: Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages, functions, and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Get data\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Step 3: Create a model and train it\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "p_pred = model.predict_proba(x)\n",
    "y_pred = model.predict(x)\n",
    "score_ = model.score(x, y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression in Python: Handwriting Recognition\n",
    "\n",
    "\n",
    "The next example will show you how to use logistic regression to solve a real-world classification problem. The approach is very similar to what you‚Äôve already seen, but with a larger dataset and several additional concerns.\n",
    "\n",
    "This example is about image recognition. To be more precise, you‚Äôll work on the recognition of handwritten digits. You‚Äôll use a dataset with 1797 observations, each of which is an image of one handwritten digit. Each image has 64 px, with a width of 8 px and a height of 8 px.\n",
    "\n",
    "The inputs (ùê±) are vectors with 64 dimensions or values. Each input vector describes one image. Each of the 64 values represents one pixel of the image. The input values are the integers between 0 and 16, depending on the shade of gray for the corresponding pixel. The output (ùë¶) for each observation is an integer between 0 and 9, consistent with the digit on the image. There are ten classes in total, each corresponding to one image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2a: Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2b: Split Data\n",
    "\n",
    "It‚Äôs a good and widely-adopted practice to split the dataset you‚Äôre working with into two subsets. These are the training set and the test set. This split is usually performed randomly. You should use the training set to fit your model. Once the model is fitted, you evaluate its performance with the test set. It‚Äôs important not to use the test set in the process of fitting the model. This approach enables an unbiased evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =\\\n",
    "    train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2c: Scale Data\n",
    "\n",
    "Standardization is the process of transforming data in a way such that the mean of each column becomes equal to zero, and the standard deviation of each column is one. This way, you obtain the same scale for all columns. Take the following steps to standardize your data:\n",
    "\n",
    "1. Calculate the mean and standard deviation for each column.\n",
    "2. Subtract the corresponding mean from each element.\n",
    "3. Divide the obtained difference by the corresponding standard deviation.\n",
    "\n",
    "It‚Äôs a good practice to standardize the input data that you use for logistic regression, although in many cases it‚Äôs not necessary. Standardization might improve the performance of your algorithm. It helps if you need to compare and interpret the weights. It‚Äôs important when you apply penalization because the algorithm is actually penalizing against the large values of the weights.\n",
    "\n",
    "You can standardize your inputs by creating an instance of StandardScaler and calling .fit_transform() on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create a Model and Train It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, multi_class='ovr', random_state=0,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=0.05, multi_class='ovr',\n",
    "                           random_state=0)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you‚Äôre working with problems with more than two classes, you should specify the multi_class parameter of LogisticRegression. It determines how to solve the problem:\n",
    "\n",
    "* 'ovr' says to make the binary fit for each class.\n",
    "* 'multinomial' says to apply the multinomial loss fit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964509394572025"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 32,  0,  0,  0,  0,  1,  0,  1,  1],\n",
       "       [ 1,  1, 33,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 28,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 29,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 39,  0,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  0,  0, 43,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 39,  0,  0],\n",
       "       [ 0,  2,  1,  2,  0,  0,  0,  1, 33,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1,  0,  2,  1, 36]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHgCAYAAAAPG9wjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6mElEQVR4nO3de3yU9Z33/9dnkhDOx4BCIiLVImIRaYoHqou1rYdWsbX3qvtz712r0q0u9bBtLdjau1rLetNurcWuUtFyu2qxYtV6QF0WpEVF8IiCWATFNCCRyEkgEPL5/ZEBAyRhorm+13zH9/PxyENmMpnrxdchn1zXTOYyd0dERESSlUk7QERE5JNAA1dERCQADVwREZEANHBFREQC0MAVEREJQANXREQkgOK0A5oq7t7ZS/r1TDsjJyVvbks7QURE8sw2PmC711lzn8urgVvSryeDJo9LOyMnFWe/lnaCiIjkmQU+u8XP6ZCyiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBJBX58P9uA7s1J1//+zXKOvYFXfn3ree5843F/Afn/sGg7qWAdC9pCMbd2zj63NuSbl2T5WnjOCSGy8gU5ThsWmzmXHDA2kntSqm3phaIa7emFohrt6YWiGu3rRaEx24ZnYq8CugCLjN3f89ye3tbGjg/y5+giUbVtO5uAMzT/oWT69dwZUL79t9m+8f+WU276hLMqPNMpkM46dcyFVfvo73qmqZ8twknnloEauWVqWd1qyYemNqhbh6Y2qFuHpjaoW4etNsTeyQspkVATcDpwFHAOeZ2RFJbQ+gpm4zSzasBmBL/Xbe3FTDAR277XGbU8uH8UjV4iQz2mzIqEOpXr6GNSvXUr+jnrkz5nP82Mq0s1oUU29MrRBXb0ytEFdvTK0QV2+arUk+hzsKWO7uK9x9O/B7YGyC29vDgM49GdqjPy+//7fd11X2OZh1dR/w9ge1oTJyUlbem5qqdbsvv1dVS1l5nxSLWhdTb0ytEFdvTK0QV29MrRBXb5qtSQ7ccuCdJperstclrnNRB24a9ff8++JZfFD/4eHjr1QcmXd7twBm+17n7uFDchRTb0ytEFdvTK0QV29MrRBXb5qtSQ7cZv5a7PO3MrNxZrbIzBbVb9zysTdabBl+dczf86eqxTxZvXT39UWW4YsDhvJY1Wsfexvtraaqlr4VH/6EVVbRm3XV+bUX3lRMvTG1Qly9MbVCXL0xtUJcvWm2Jjlwq4CDmlyuAKr3vpG7T3X3SnevLO7e+WNv9Kcjx7Ji03tMX/7MHtcf13cwKze/x7vbNn7sbbS3ZQuXU35Yfw4c1I/ikmLGnDOaZx5alHZWi2LqjakV4uqNqRXi6o2pFeLqTbM1yVcpLwQOM7NDgL8B5wL/kOD2GNlnIGMHHsWyDe9y/0n/AsCNS2Yz792/cnrFkTzyzqtJbv4ja9jZwJTx05g062oyRRkev2MOby/Jv1f37RJTb0ytEFdvTK0QV29MrRBXb5qtluSxazM7HbiRxl8Lut3dr2/t9p0OHeCDJo9LrKc9VZydf4emRUQkXQt8Nhu9trmnVJP9PVx3fxR4NMltiIiIxEBv7SgiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEkOgJ6Nuq5M1tVJz9WtoZOen7dM+0E9qk5vj1aSeItJmVlqadkDOvq0s7oU1iWtuo1FmLn9IeroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhJAXp2Avr1VnjKCS268gExRhsemzWbGDQ+knbRbiRVzzbDvU2zFFFkRC2qfZ2bVQ/zDwG8wstdw6ht28m5dDbe+eQdbdm5NO3cf+by2e4upFeLqjan1ylsu5tjTRrC+ZiPjKieknbNfWtvkpNWb2B6umd1uZmvN7NWkttGaTCbD+CkXMvH067lo2BWcdO5oBg6tSCOlWTu8np8u+QUTFl/LhMXXclTPYRzadTCLNyzh+y//H36w+Ces3vYuZ5afnnbqPvJ9bZuKqRXi6o2pFeDJO+cxcezktDNyorVNVlq9SR5S/h1waoL336ohow6levka1qxcS/2OeubOmM/xYyvTymlWXUMdAEVWRJEV4TiLNyyhgQYAlm9aQZ8OvdJMbFYMa7tLTK0QV29MrQCL5y9jU+3mtDNyorVNVlq9iQ1cd58H1CZ1//tTVt6bmqp1uy+/V1VLWXmftHKaZRg/+8w13PLZX7B4w1Le3Lxyj8+P6Teal9YvTqmuZTGs7S4xtUJcvTG1xkZrW5gK9jlcs32vc/fwIa1wnImLr6VzUSeu+PQlVHQaQNXWagDGDjidnd7A/PcWpFy5rxjWdpeYWiGu3phaY6O1LUypv0rZzMaZ2SIzW7SDuna735qqWvpWfPgTYVlFb9ZVp7bD3aotO7eydOMbHNXzSABOKDuOkb2Gc/Py21Iua15MaxtTK8TVG1NrbLS2hSn1gevuU9290t0rSyhtt/tdtnA55Yf158BB/SguKWbMOaN55qFF7Xb/H1e34q50LuoEQImVcGSPoVRvXcPwHsM4Y8Cp/HzZFLY3bE+5snn5vrZNxdQKcfXG1BobrW1hKthDyg07G5gyfhqTZl1NpijD43fM4e0lVWln7dazQw++/alvkiGDmfHsukW8uP4V/mPE9ZRYMROGXgnA8s0ruH3lf6Vcu6d8X9umYmqFuHpjagWYMP1Shp8wlB5lXblr+U3ced1MZk1/Ku2sZmltk5VWryX1vICZ3QOMAcqAd4Efu/u01r6mu/X2Y+zkRHraW9+ne6ad0CY1x69PO0Gkzay0/Y56Jc3r2u8psRBiWtuYPFv3GBsb1jXzLHyCe7jufl5S9y0iIhKb1J/DFRER+STQwBUREQlAA1dERCQADVwREZEANHBFREQC0MAVEREJQANXREQkAA1cERGRADRwRUREAtDAFRERCUADV0REJAANXBERkQA0cEVERALQwBUREQlAA1dERCQADVwREZEANHBFREQCKE47YA9mWGlp2hU5ee+krWkntMmnFnZMOyFnKz7vaSe0idfVpZ1QsLS2ydHaJsRb/v6lPVwREZEANHBFREQC0MAVEREJQANXREQkAA1cERGRADRwRUREAtDAFRERCUADV0REJAANXBERkQA0cEVERALQwBUREQlAA1dERCQADVwREZEANHBFREQC0MAVEREJQANXREQkgPw6AX07uvKWizn2tBGsr9nIuMoJaefsV773FlsJ3x1yNcVWQsYyvPD+Qh5efT9nDDibo3qMxHE21W9k+ltT2bBjfdq5e8j3td1b5SkjuOTGC8gUZXhs2mxm3PBA2kktiqkV4uqNqRXi6k2rNbE9XDM7yMzmmNlSM3vNzC5LalvNefLOeUwcOznkJj+WfO+t9x388o1J/HTp1fx0yQ8Z1mM4h3T5FE+ueYSfLr2a65f+kMXrX+Ir/c9KO3Uf+b62TWUyGcZPuZCJp1/PRcOu4KRzRzNwaEXaWc2KqRXi6o2pFeLqTbM1yUPK9cC/uftQ4FjgUjM7IsHt7WHx/GVsqt0canMfWwy9dQ11ABRZEUVWhDtsa9i2+/MdikrxtOJaEcPa7jJk1KFUL1/DmpVrqd9Rz9wZ8zl+bGXaWc2KqRXi6o2pFeLqTbM1sYHr7qvd/YXsnzcBS4HypLYnyTOMq4f+lMlH3czSja/y1pY3ARg74Bv87DM3Mqr38fypembKlXErK+9NTdW63Zffq6qlrLxPikUti6kV4uqNqRXi6k2zNciLpsxsEHA0sCDE9iQZjnP90h8yYfFlDOoymAEdGw/DPFh9HxMXX85ztU8zpu+XUq6Mm9m+17nn43GDuFohrt6YWiGu3jRbEx+4ZtYVmAlc7u4bm/n8ODNbZGaLdvi2fe9A8s7WnVt4Y9PrDOsxfI/rF9Y+zdG9PpdSVWGoqaqlb8WHP22XVfRmXXVtikUti6kV4uqNqRXi6k2zNdGBa2YlNA7bu9z9/uZu4+5T3b3S3StLrGOSOfIxdC3uRqeizgCUWAmHdxvGmm3V9Cs9YPdthvcYybvbqtNKLAjLFi6n/LD+HDioH8UlxYw5ZzTPPLQo7axmxdQKcfXG1Apx9abZmtivBZmZAdOApe7+H0ltpyUTpl/K8BOG0qOsK3ctv4k7r5vJrOlPhc7IWb739ijpyT8NGkeGDGYZnn9/AYs3vMS4wd/hgI79cW+gdvs67l51R9qp+8j3tW2qYWcDU8ZPY9Ksq8kUZXj8jjm8vaQq7axmxdQKcfXG1Apx9abZakkduzazzwN/BhYDDdmrJ7r7oy19TfdMHz+29LREej7pBv+lmScu8tSKz+fncz8t8bq6tBNEJE8s8Nls9Npmv+Emtofr7n8B4vkuLyIikiC9taOIiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISQGInoP9I3PG6urQrCtKKz5emnZCztX8YlHZCm/Q9c1naCSISAe3hioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgHk1wno21nlKSO45MYLyBRleGzabGbc8EDaSS2KqfXKWy7m2NNGsL5mI+MqJ6Sds48DOvbgpyPOpk9pVxxn5qpF3L3yGYZ0P5CrPzOW0kwx9d7ApFcf4tX1f0s7dx8xPRZiaoW4emNqhbh602pNbA/XzDqa2XNm9rKZvWZmP0lqW83JZDKMn3IhE0+/nouGXcFJ545m4NCKkAk5i6kV4Mk75zFx7OS0M1q003fyiyWP8fWnbuIf/3Ir5xx8DIO79uXyoady6xv/wzl/vpn/fGM2lw89Ne3UfcT0WIipFeLqjakV4upNszXJQ8p1wBfc/ShgBHCqmR2b4Pb2MGTUoVQvX8OalWup31HP3BnzOX5sZajNt0lMrQCL5y9jU+3mtDNa9F7dZl7fuBqALTu3s2JzDf06dsfd6VJcCkDX4o7UbNuYZmazYnosxNQKcfXG1Apx9abZmtjA9Ua7viuXZD88qe3tray8NzVV63Zffq+qlrLyPqE23yYxtcZmQKeeHN6jP4vXVzF5yaNcccSpzDr5e1x5xKnc9PqTaeftI6bHQkytEFdvTK0QV2+arYm+aMrMiszsJWAt8KS7L0hye3tue9/r3IPN+zaJqTUmnYo68PPPnsfk1x7lg/o6/tfBo/j5a49y6uzJ/Py1R/nx8K+lnbiPmB4LMbVCXL0xtUJcvWm2Jjpw3X2nu48AKoBRZnbk3rcxs3FmtsjMFu2grt22XVNVS9+KD39qKavozbrq2na7//YUU2ssii3DLz57Ho/+7WX+Z80SAM6oOJrZ2T8/sfpVjuxZnmZis2J6LMTUCnH1xtQKcfWm2Rrk14LcfT0wF9jnVSruPtXdK929soTSdtvmsoXLKT+sPwcO6kdxSTFjzhnNMw8tarf7b08xtcbix0d9jZWba/ivlU/vvq5m20Yq+xwCwKg+g1n1wbqWvjw1MT0WYmqFuHpjaoW4etNsTezXgsysL7DD3debWSfgi8ANSW1vbw07G5gyfhqTZl1NpijD43fM4e0lVaE23yYxtQJMmH4pw08YSo+yrty1/CbuvG4ms6Y/lXbWbiN6HcwZFUfzxsY1zDjhUgB+vexJrn3lQb4/7HSKMhm276znusUPply6r5geCzG1Qly9MbVCXL1ptlpSx67NbDgwHSiicU/6Xne/trWv6W69/Rg7OZGeTzorbb+jB0lb+4dBaSe0Sd8zl6WdICJ5YoHPZqPXNvNMcYJ7uO7+CnB0UvcvIiISE721o4iISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAxWkHSBheV5d2Qs76nrks7YQ22TxrcNoJOet66oq0EwqWlZamndAmMX1PKBTawxUREQlAA1dERCQADVwREZEANHBFREQC0MAVEREJQANXREQkAA1cERGRANo0cM0sY2bdk4oREREpVPsduGZ2t5l1N7MuwBJgmZl9L/k0ERGRwpHLHu4R7r4ROAt4FBgI/GOSUSIiIoUml4FbYmYlNA7cB919R7JJIiIihSeXgXsr8BbQBZhnZgcDG5KMEhERKTS5DNw/uXu5u5/u7g6sAr6ZcJeIiEhByWXgzmx6ITt0f59MjoiISGFq8fR8ZnY4MAzoYWZfb/Kp7kDHpMNEREQKSWvnwx0CfBXoCZzR5PpNwMUJNomIiBScFgeuuz8IPGhmx7n7MwGb2k3lKSO45MYLyBRleGzabGbc8EDaSS2KqRXi6s331n6lPbjmM+fQp0M3GnAerFrAvavmc2jX/nz/iK/RuagDq7e9z49f+T1bdubXScPzfW33FlPvlbdczLGnjWB9zUbGVU5IO2e/YlrbtFpzeQ53nJndvvdHrhswsyIze9HMHv4YnW2WyWQYP+VCJp5+PRcNu4KTzh3NwKEVIRNyFlMrxNUbQ+tOb+CmZQ9z3tO/4OIFUzj7oOMY1KUfE4adzX/+9THOf+ZGnnr3Nc4f9Hdpp+4hhrVtKrbeJ++cx8Sxk9POyElMa5tmay4D92HgkezHbBqfw93chm1cBixte9rHM2TUoVQvX8OalWup31HP3BnzOX5sZeiMnMTUCnH1xtC6bvsm3thUDcCWndt564O19C3twcFd+vLi+ysBeG7dXxlzwJFpZu4jhrVtKrbexfOXsam2Ld9q0xPT2qbZut+B6+4zm3zcBfw9kNO/fDOrAL4C3PbxMtuurLw3NVXrdl9+r6qWsvI+oTNyElMrxNUbUyvAgR178elu5by2YRUrNr/LCX2PAOALBw6nX8ee6cbtJba1ja03JjGtbZqtH+VsQYfR+PaOubgR+D7Q8BG287GY7Xtd42805Z+YWiGu3phaOxV1YNKI87lx2UNs2VnH9a/+gbMPOo47jh1P56JS6hvq007cQ0xrC/H1xiSmtU2ztbVXKQNgZpsAByz73zXAVTl83VeBte7+vJmNaeV244BxAB3pnFN0Lmqqaulb8eFPLWUVvVlXXdtu99+eYmqFuHpjaS2yDD876h95fPVLPLX2NQDe3lLD5S9MA+CgzmWM7nt4mon7iGVtd4mtNyYxrW2arbkcUu7m7t2b/PfT7j5zf18HjAbONLO3aHyjjC+Y2X81c/9T3b3S3StLKG3zX6AlyxYup/yw/hw4qB/FJcWMOWc0zzy0qN3uvz3F1Apx9cbSevWwb/D2B2v5/dt/3n1drw5dADCMCwZ/gT++82xaec2KZW13ia03JjGtbZqt+93DBci+8cXnadzD/bO7P7C/r3H3CcCE7NePAb7r7ud/1NC2atjZwJTx05g062oyRRkev2MOby+pCrX5NompFeLqjaF1eM9BnDbgsyzftJrpx14GwC3LZ3FQ5zLOPug4AOaufZWHq/PrG1gMa9tUbL0Tpl/K8BOG0qOsK3ctv4k7r5vJrOlPpZ3VrJjWNs1W29+xazP7DXAocE/2qnOAN9390pw38uHA/Wprt+tuvf0YOznXuxXJC5tnDU47IWddT12RdkLBstL2O0IXgtfl1+90F4oFPpuNXtvMM8W57eH+HXBk9j2UMbPpwOK2BLj7XGBuW75GRESkkOTyKuVl7Pmq5IOAV5LJERERKUy57OH2AZaa2XPZy58DnjWzhwDc/cyk4kRERApFLgP3msQrREREClwuA/d0d9/j927N7Ia9rxMREZGW5fIc7peaue609g4REREpZK2dgP7bwCXAp8ys6YukugFPJx0mIiJSSFo7pHw38BgwCfhBk+s3uXt+vmeXiIhInmrtBPQbgA1mtvdztV3NrKu7r0o2TUREpHDk8qKpR/jw5AUdgUNo/N3cYQl2iYiIFJT9Dlx3/0zTy2Y2EvhWYkUiIiIFqM3nw3X3F2h88wsRERHJUS7nw72yycUMMBKoSaxIRESkAOXyHG63Jn+up/E53VzOhysiIiJZuTyH+xMAM+vWeNE3J14lIiJSYPb7HK6ZHWlmLwKvAq+Z2fNmdmTyaSIiIoUjlxdNTQWudPeD3f1g4N+y14mIiEiOcnkOt4u7z9l1wd3nmlmXBJtEotL11BVpJ+TsmhUvpJ3QJtcOHpl2Qs68ri7thIJlpaVpJ+Suzlr8VC4Dd4WZ/Qi4M3v5fGBlO2SJiIh8YuRySPmbQF/g/uxHGXBBklEiIiKFJpdXKb8PfCdAi4iISMFq8ztNiYiISNtp4IqIiASggSsiIhJAi8/hmtmvaTwtX7PcXc/rioiI5Ki1F00tClYhIiJS4FocuO4+PWSIiIhIIcvl9Hx9gauAI4COu6539y8k2CUiIlJQcnnR1F3AUuAQ4CfAW8DCBJtEREQKTi4Dt4+7TwN2uPtT7v5N4NiEu0RERApKLu+lvCP739Vm9hWgGqhILklERKTw5DJwf2pmPWg8Ld+vge7AFYlWiYiIFJhc3kv54ewfNwAnJZsjIiJSmHJ5lfIdNPMGGNnnckVERCQHubxo6mHgkezHbBoPKW9OMqq9VJ4ygtuX/orfvfFrzrnqrLRzWhVTK8TVG1Mr5HevWQdG9L+fowc8zMgBjzGw52UAdCk5nKMO/AMjBzzKEf2mUmRdUy5tXj6v7d5iaoW4eq+85WLufftmpi6aFHS7+x247j6zycddwN8DR+Zy52b2lpktNrOXzCzoO1dlMhnGT7mQiadfz0XDruCkc0czcGh+vtYrplaIqzemVsj/XvftvLLmfF6s/iovVp9Br04n0q10BIeVTeKt9yfzQvXprNvyBBU9Lk47dR/5vrZNxdQK8fU+eec8Jo6dHHy7H+XkBYcBA9tw+5PcfYS7V36EbX1kQ0YdSvXyNaxZuZb6HfXMnTGf48cGTchZTK0QV29MrRBHb4NvAcCsmAzF4E6nkkPYUPccAO9vnU9Z51PSTGxWDGu7S0ytEF/v4vnL2FQb/kDtfgeumW0ys427PoA/0fjOU3mtrLw3NVXrdl9+r6qWsvI+KRa1LKZWiKs3plaIpTfD0QP+xLEHPcf72+azafvLbNn+V3p3+iIAfbucRofi/ik37iuOtW0UUyvE15uWXF6l3O1j3L8DT5iZA7e6+9SPcV9tYtZMjLd48qNUxdQKcfXG1Aqx9DbwYvUZFGW6cUTfW+hc8mneWHcVn+p9DQN7jqd2y3/jvmP/dxNYHGvbKKZWiK83Lbm8Snm2u5+8v+taMNrdq82sH/Ckmb3u7vP2uq9xwDiAjnRuQ3rraqpq6Vvx4U9YZRW9WVdd2273355iaoW4emNqhbh6dzZsYsO2Z+nV6UT+tvE2Xn33nwHoVDyI3p3z7zcIY1rbmFohvt60tHhI2cw6mllvoMzMeplZ7+zHIGBALnfu7tXZ/64F/giMauY2U9290t0rSyj9SH+J5ixbuJzyw/pz4KB+FJcUM+ac0TzzUH6ecTCmVoirN6ZWyP/ekkxvijKNB70yVkrPTqPZuuNNSjK7vtkaB/X8V1Zvuju9yBbk+9o2FVMrxNebltb2cL8FXE7jcH0e2HXQYCNw8/7u2My6ABl335T985eBaz9WbRs07GxgyvhpTJp1NZmiDI/fMYe3l1SF2nybxNQKcfXG1Ar531tS1JchZZMxKwIyvPfBI9RuncOAbv9M/+7nA7Buy+O8u/m+dEObke9r21RMrRBf74TplzL8hKH0KOvKXctv4s7rZjJr+lOJb9f2d5zdzMa7+6/bfMdmg2ncq4XGwX63u1/f2td0t95+jOVypFpEPoprVryQdkKbXDt4ZNoJkgestP2Ofibt2brH2NiwrplntXN7L+UGM+vp7usBzKwXcJ67/6a1L3L3FcBRbY0VEREpRLn8Hu7Fu4YtgLu/D+Tfb7WLiIjksVwGbsbswxd9W+OTNx2SSxIRESk8uRxSfhy418xuofH3av8FmJVolYiISIHJZeBeRePvyX6bxlcqPwH8NskoERGRQpPLyQsa3P0Wd/+Gu58NvEbjiehFREQkR7ns4WJmI4DzgHOAlcD9CTaJiIgUnBYHrpl9GjiXxkG7DphB4+/t5t97tomIiOS51vZwXwf+DJzh7ssBzOyKIFUiIiIFprXncM8G1gBzzOy3ZnYyH769o4iIiLRBiwPX3f/o7ucAhwNzgSuAA8zsP83sy4H6RERECkIur1L+wN3vcvevAhXAS8APkg4TEREpJLm809Ru7l7r7re6+xeSChIRESlEbRq4IiIi8tFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIB5PReyrIvKy1NO6FNvK4u7QTJA9cOHpl2Qps8Xv1S2gk5O2XAiLQTClZU37/cW/yU9nBFREQC0MAVEREJQANXREQkAA1cERGRADRwRUREAtDAFRERCUADV0REJAANXBERkQA0cEVERALQwBUREQlAA1dERCQADVwREZEANHBFREQC0MAVEREJQANXREQkAA1cERGRAAp64FaeMoLbl/6K373xa8656qy0c1p15S0Xc+/bNzN10aS0U3IS09rG1Apx9cbRmsH6PIj1nAqAdb0c6/MnrM9DWK87INMv5b7mxbG2H4qpN63WRAeumfU0s/vM7HUzW2pmxyW5vaYymQzjp1zIxNOv56JhV3DSuaMZOLQi1Obb7Mk75zFx7OS0M3IS09rG1Apx9UbT2vmfoP7N3Rf9g9vwdWfg687E6+ZgXf81xbjmRbO2WTH1ptma9B7ur4BZ7n44cBSwNOHt7TZk1KFUL1/DmpVrqd9Rz9wZ8zl+bGWozbfZ4vnL2FS7Oe2MnMS0tjG1Qly9UbRmDsRKx+Bb7/3wOm/y78w6AR48a3+iWNsmYupNszWxgWtm3YETgWkA7r7d3dcntb29lZX3pqZq3e7L71XVUlbeJ9TmC1pMaxtTK8TVG0Ordb8a3/R/gYY9r+96BdZ3HtbxTHzTr9KJa0UMa9tUTL1ptia5hzsYqAHuMLMXzew2M+uS4Pb2YLbvde7595NsjGJa25haIa7evG8tPQka1kH9a/t8yjf/Eq85Ed/2ENbl/BTiWpf3a7uXmHrTbE1y4BYDI4H/dPejgQ+AH+x9IzMbZ2aLzGzRDurabeM1VbX0rfjwp5ayit6sq65tt/v/JItpbWNqhbh6873VSkZC6clY3zlYjxuh9Fisx8/3vNHWP0HpKan0tSbf13ZvMfWm2ZrkwK0Cqtx9QfbyfTQO4D24+1R3r3T3yhJK223jyxYup/yw/hw4qB/FJcWMOWc0zzy0qN3u/5MsprWNqRXi6s33Vt/8C7zmBLzmJHzD5VD3LL7hu1B08Ic36ngy7FyRWmNL8n1t9xZTb5qtxUndsbuvMbN3zGyIuy8DTgaWJLW9vTXsbGDK+GlMmnU1maIMj98xh7eXVIXafJtNmH4pw08YSo+yrty1/CbuvG4ms6Y/lXZWs2Ja25haIa7emFqbsm7fg6JDgAbYWY1vvCbtpH3EtrYx9abZakkeuzazEcBtQAdgBXCBu7/f0u27W28/xk5OrKc9WWn77Y2H4HXtd7heJJTHq19KOyFnpwwYkXaC5IEFPpuNXtvMM8UJ7uECuPtLQH6+NlxERCSggn6nKRERkXyhgSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBJHoC+kLmdXVpJ4gUvFMGjEg7IWfXrHgh7YQ2uXbwyLQTPnG0hysiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEUNADt/KUEdy+9Ff87o1fc85VZ6Wd06qYWiGu3phaIa7emFohv3vNOjCi//0cPeBhRg54jIE9LwOgS8nhHHXgHxg54FGO6DeVIuuacmnz8nlt95ZWa2ID18yGmNlLTT42mtnlSW1vb5lMhvFTLmTi6ddz0bArOOnc0QwcWhFq820SUyvE1RtTK8TVG1Mr5H+v+3ZeWXM+L1Z/lRerz6BXpxPpVjqCw8om8db7k3mh+nTWbXmCih4Xp526j3xf26bSbE1s4Lr7Mncf4e4jgM8CW4A/JrW9vQ0ZdSjVy9ewZuVa6nfUM3fGfI4fWxlq820SUyvE1RtTK8TVG1MrxNHb4FsAMCsmQzG406nkEDbUPQfA+1vnU9b5lDQTmxXD2u6SZmuoQ8onA2+6+9uBtkdZeW9qqtbtvvxeVS1l5X1Cbb5NYmqFuHpjaoW4emNqhVh6Mxw94E8ce9BzvL9tPpu2v8yW7X+ld6cvAtC3y2l0KO6fcuO+4ljbRmm2hhq45wL3BNoWAGb7XufuIRNyFlMrxNUbUyvE1RtTK8TS28CL1WewoGo03TocReeST/PGuqsY0P18RvR/kCLrgvuOtCP3EcfaNkqztTjpDZhZB+BMYEILnx8HjAPoSOd2225NVS19Kz78qaWsojfrqmvb7f7bU0ytEFdvTK0QV29MrRBX786GTWzY9iy9Op3I3zbexqvv/jMAnYoH0bvzSenGNSOmtU2zNcQe7mnAC+7+bnOfdPep7l7p7pUllLbbRpctXE75Yf05cFA/ikuKGXPOaJ55aFG73X97iqkV4uqNqRXi6o2pFfK/tyTTm6JMNwAyVkrPTqPZuuNNSjK7hoNxUM9/ZfWmu9OLbEG+r21TabYmvocLnEfgw8kADTsbmDJ+GpNmXU2mKMPjd8zh7SVVoTNyElMrxNUbUyvE1RtTK+R/b0lRX4aUTcasCMjw3gePULt1DgO6/TP9u58PwLotj/Pu5vvSDW1Gvq9tU2m2WpLHrs2sM/AOMNjdN+zv9t2ttx9jJyfWIyKSlGtWvJB2QptcO3hk2gkFaYHPZqPXNvNMccJ7uO6+BcjPl6qJiIgEVNDvNCUiIpIvNHBFREQC0MAVEREJQANXREQkAA1cERGRADRwRUREAtDAFRERCUADV0REJAANXBERkQA0cEVERALQwBUREQlAA1dERCQADVwREZEANHBFREQC0MAVEREJQANXREQkAA1cERGRAIrTDohVUc8eaSe0ScPWbWkn5CzTqWPaCW2yc/2GtBMkD1w39Li0E9rkUwst7YScvfm5eL5/tUZ7uCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgABX0C+spTRnDJjReQKcrw2LTZzLjhgbSTmlVW3ovv/eZCeh3QA29o4NHp83jw1tlpZ7Xoylsu5tjTRrC+ZiPjKiekndOq2NYW4nncQlytEFdvvv87K7YSvjvkaoqthIxleOH9hTy8+n7OGHA2R/UYieNsqt/I9LemsmHH+rRz95DW4yDRgWtmVwAXAQ4sBi5w921JbnOXTCbD+CkXctWXr+O9qlqmPDeJZx5axKqlVSE23yYN9Q389kf3svyVVXTqWsqv/+dHvDh3CauWrU47rVlP3jmPh255ku/f9q20U/YrtrWN6XEbUyvE15vv/87qfQe/fGMSdQ11ZCjie4f/iNc2vsyTax7hT9UzATip75f5Sv+zuHvV79KNbSLNx0Fih5TNrBz4DlDp7kcCRcC5SW1vb0NGHUr18jWsWbmW+h31zJ0xn+PHVobafJvUvruB5a+sAmDr5jreeWM1ffr3SrmqZYvnL2NT7ea0M3IS29rG9LiNqRXi643h31ldQx0ARVZEkRXhDtsaPtyn6lBUiqcV14I0HwdJH1IuBjqZ2Q6gM1Cd8PZ2KyvvTU3Vut2X36uq5fBjDgu1+Y/sgIP68KnhA1n2/Iq0UwpODGsb0+M2plaIrzcGhjFx6HX0LT2Ap2r+m7e2vAnA2AHf4Jg+n2frzq388o2fpVy5pzQfB4nt4br734CfA6uA1cAGd38iqe3tzazZplCb/0g6dinlh9Mv4daJM9iyKciR90+MWNY2psdtTK0QX28MHOf6pT9kwuLLGNRlMAM6VgDwYPV9TFx8Oc/VPs2Yvl9KuXJPaT4Okjyk3AsYCxwCDAC6mNn5zdxunJktMrNFO6hrt+3XVNXSt6LP7stlFb1ZV13bbvff3oqKi/jR9G8z575nmf/wC2nnFJSY1jamx21MrRBfb0y27tzCG5teZ1iP4Xtcv7D2aY7u9bmUqpqX5uMgyV8L+iKw0t1r3H0HcD9w/N43cvep7l7p7pUllLbbxpctXE75Yf05cFA/ikuKGXPOaJ55aFG73X97u+Kmf2LVG6u5/zdPpp1ScGJa25getzG1Qny9+a5rcTc6FXUGoMRKOLzbMNZsq6Zf6QG7bzO8x0je3RbsmcScpPk4SPI53FXAsWbWGdgKnAwEe3Q37GxgyvhpTJp1NZmiDI/fMYe3l+TnqxGHHXMoXzz3eFa+VsXNT10DwO+u+yML/3txymXNmzD9UoafMJQeZV25a/lN3HndTGZNfyrtrGbFtrYxPW5jaoX4evP931mPkp7806BxZMhgluH59xeweMNLjBv8HQ7o2B/3Bmq3r+PuVXeknbqHNB8HluSxazP7CXAOUA+8CFzk7i0eN+5uvf0YOzmxnvZU1LNH2glt0rA1f5+33FumU8e0E9pk5/oNaSdIHrDS9jtCF8LgvzTzZGaeevNz8Xz/WuCz2ei1zS5uoq9SdvcfAz9OchsiIiIx0Fs7ioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgEkegL6QrZz/Ya0EwpWQ9oBBcxKS9NOaBOvq0s7IWeZTh3TTmiTFZ/flnZCzs5csi7thJwt+0Z9i5/THq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISQEGfgL7ylBFccuMFZIoyPDZtNjNueCDtpBbF1Apx9V55y8Uce9oI1tdsZFzlhLRz9ktrm5xY1rasvBff+82F9DqgB97QwKPT5/HgrbPTzmpRvj8OiqyEswf+iiIrwayINzc9xYL3pgMwvNfXGN7zLBrYyVubn+XpmqmJdSS6h2tml5nZq2b2mpldnuS29pbJZBg/5UImnn49Fw27gpPOHc3AoRUhE3IWUyvE1/vknfOYOHZy2hk50domJ6a1bahv4Lc/updxx/6Iy7/8M8648CQGDumfdlaL8v1xsNN38MdVV3LPWxfz+5UXM7DLKA7oOJTyziMY3PV47n7rIu5e+U1erL030Y7EBq6ZHQlcDIwCjgK+amaHJbW9vQ0ZdSjVy9ewZuVa6nfUM3fGfI4fWxlq820SUyvE17t4/jI21W5OOyMnWtvkxLS2te9uYPkrqwDYurmOd95YTZ/+vVKualkMj4Mdvg2AjBWTsWLA+UzPM3l+3T00+A4Atu5cn2hDknu4Q4Fn3X2Lu9cDTwFfS3B7eygr701N1brdl9+rqqWsvE+ozbdJTK0QX29MtLbJiXVtDzioD58aPpBlz69IOyVqRoZzB03lwsPu550PFvHuttfp2aGCAZ0/w/86+Ga+PvCX9Os4JNGGJAfuq8CJZtbHzDoDpwMHJbi9PZjte527h9p8m8TUCvH1xkRrm5wY17Zjl1J+OP0Sbp04gy2btqWdEzWngd+/NY47lv89B3Q8nN4dBpGxIkoz3fjD25cyf+2tnDrgmkQbEnvRlLsvNbMbgCeBzcDLQP3etzOzccA4gI50brft11TV0rfiw59eyyp6s666tt3uvz3F1Arx9cZEa5uc2Na2qLiIH03/NnPue5b5D7+Qdk7B2N7wAX/b8jIHdx3F5h01vLn5zwC8u+11wOlY1INtOzcksu1EXzTl7tPcfaS7nwjUAn9t5jZT3b3S3StLKG23bS9buJzyw/pz4KB+FJcUM+ac0Tzz0KJ2u//2FFMrxNcbE61tcmJb2ytu+idWvbGa+3/zZNop0etY1IMOmS4AFFkHDuoykvfrVrFi83wqOh8NQM+SCjJWnNiwhYR/LcjM+rn7WjMbCHwdOC7J7TXVsLOBKeOnMWnW1WSKMjx+xxzeXlIVavNtElMrxNc7YfqlDD9hKD3KunLX8pu487qZzJr+VNpZzdLaJiemtR12zKF88dzjWflaFTc/1XiY83fX/ZGF/7045bLm5fvjoEtxH77U/yqMDGYZ/rpxLm998CwZijm5//f4h0OmsdPr+e/VNyTaYUk+h2Fmfwb6ADuAK9291V8k6269/Rg7ObEeiYOVtt+RjhC8ri7thJxpbZNT1LNH2glt0rA1nueEz3ixOu2EnE3+xiJWvbqxmVcMJLyH6+4nJHn/IiIisdBbO4qIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEoIErIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAAauCIiIgFo4IqIiASggSsiIhKABq6IiEgAGrgiIiIBaOCKiIgEYO6edsNuZlYDvN3Od1sGvNfO95mkmHpjaoW4emNqhbh6Y2qFuHpjaoVkeg92977NfSKvBm4SzGyRu1em3ZGrmHpjaoW4emNqhbh6Y2qFuHpjaoXwvTqkLCIiEoAGroiISACfhIE7Ne2ANoqpN6ZWiKs3plaIqzemVoirN6ZWCNxb8M/hioiI5INPwh6uiIhI6gp64JrZqWa2zMyWm9kP0u5pjZndbmZrzezVtFv2x8wOMrM5ZrbUzF4zs8vSbmqJmXU0s+fM7OVs60/SbsqFmRWZ2Ytm9nDaLa0xs7fMbLGZvWRmi9Lu2R8z62lm95nZ69nH73FpNzXHzIZk13TXx0YzuzztrtaY2RXZf2Ovmtk9ZtYx7aaWmNll2c7XQq5rwR5SNrMi4A3gS0AVsBA4z92XpBrWAjM7EdgM/D93PzLtntaYWX+gv7u/YGbdgOeBs/Jxbc3MgC7uvtnMSoC/AJe5+7Mpp7XKzK4EKoHu7v7VtHtaYmZvAZXuHsXvXprZdODP7n6bmXUAOrv7+pSzWpX9XvY34Bh3b+/3KWgXZlZO47+tI9x9q5ndCzzq7r9Lt2xfZnYk8HtgFLAdmAV8293/mvS2C3kPdxSw3N1XuPt2Ghd4bMpNLXL3eUBt2h25cPfV7v5C9s+bgKVAebpVzfNGm7MXS7Ifef1TpplVAF8Bbku7pZCYWXfgRGAagLtvz/dhm3Uy8Ga+DtsmioFOZlYMdAaqU+5pyVDgWXff4u71wFPA10JsuJAHbjnwTpPLVeTpUIiZmQ0CjgYWpJzSouzh2ZeAtcCT7p63rVk3At8HGlLuyIUDT5jZ82Y2Lu2Y/RgM1AB3ZA/X32ZmXdKOysG5wD1pR7TG3f8G/BxYBawGNrj7E+lWtehV4EQz62NmnYHTgYNCbLiQB641c11e79nExsy6AjOBy919Y9o9LXH3ne4+AqgARmUPKeUlM/sqsNbdn0+7JUej3X0kcBpwafapkXxVDIwE/tPdjwY+APL9tR0dgDOBP6Td0hoz60XjEcRDgAFAFzM7P92q5rn7UuAG4EkaDye/DNSH2HYhD9wq9vyppYL8PcQRnezzoTOBu9z9/rR7cpE9fDgXODXdklaNBs7MPjf6e+ALZvZf6Sa1zN2rs/9dC/yRxqdy8lUVUNXkCMd9NA7gfHYa8IK7v5t2yH58EVjp7jXuvgO4Hzg+5aYWufs0dx/p7ifS+FRe4s/fQmEP3IXAYWZ2SPanxHOBh1JuKgjZFyJNA5a6+3+k3dMaM+trZj2zf+5E4zeG11ONaoW7T3D3CncfRONj9n/cPS/3FMysS/ZFc2QPzX6ZxsN1ecnd1wDvmNmQ7FUnA3n3Qr+9nEeeH07OWgUca2ads98fTqbxtR15ycz6Zf87EPg6gda4OMRG0uDu9Wb2r8DjQBFwu7u/lnJWi8zsHmAMUGZmVcCP3X1aulUtGg38I7A4+9wowER3fzS9pBb1B6ZnX+mZAe5197z+VZuIHAD8sfH7K8XA3e4+K92k/RoP3JX9IXwFcEHKPS3KPr/4JeBbabfsj7svMLP7gBdoPDz7Ivn9rlMzzawPsAO41N3fD7HRgv21IBERkXxSyIeURURE8oYGroiISAAauCIiIgFo4IqIiASggSsiIhKABq7Ix2RmO7NndHnVzP6Q/XWOj3pfvzOzb2T/fJuZHdHKbceYWZvfXCB7hp+yj9rY5H7Oaq0vh6/vaWaXfNwOkVho4Ip8fFvdfUT2LE/bgX9p+sns7wC3mbtftJ8zMI0h3XfzOQv4yAMX6Alo4MonhgauSPv6M3Bodu9zjpndTeMbhBSZ2WQzW2hmr5jZt6DxXbvMbIqZLTGzR4B+u+7IzOaaWWX2z6ea2QvWeF7f2dmTRvwLcEV27/qE7LtqzcxuY6GZjc5+bR8zeyL7hv230vz7jGNm51njuW1fNbMbmly/ucmfv5HdCz+exvf4nZzd/qeyvTea2dPZ+xiV/Zr/Y2bfbXIfr2b7/x34VPbrJ5tZfzOb1+RowQnt8T9EJF8U7DtNiYSWPS3ZaTS+ITo0vq/wke6+MnsmnQ3u/jkzKwXmm9kTNJ5paQjwGRrfuWkJcPte99sX+C1wYva+ert7rZndAmx2959nb3c38Et3/0v2Lesep/FUZD8G/uLu15rZV4B9zupjZgNofEP3zwLv03gGoLPc/YHm/q7u/rSZPQQ87O73Ze8DGs89fHz2JAa3A62dKOIH2fUZkf36fwMed/frs0cFPvKheZF8pIEr8vF1avIWl3+m8X2mjweec/eV2eu/DAzf9fws0AM4jMbzs97j7juBajP7n2bu/1hg3q77cveWzpv8ReCI7OAD6J59r+MTaXy/WNz9ETNr7m3sPgfMdfcaADO7K/t1D+zn7763e7LbmWdm3Xe9j3WOFgK3W+OJMR5w95fauG2RvKaBK/Lxbd21l7ZLduh90PQqYLy7P77X7U5n/6eNtBxuA41PER3n7lubacllGy1p+rUd93M/e2/HaXxv3aZPXzV7H9khfSLwFeBOM5vs7v9vP9sTiYaewxUJ43Hg29m9N8zs09Z4hp15wLnZ53j7Ayc187XPAH9nZodkv7Z39vpNQLcmt3sC+NddF8xsRPaP84D/L3vdaUCvZraxILuNsuzh3POAp7Kfe9fMhppZBvhak6/Ze/sA52S383kaD6FvAN4iexo8MxtJ4zlT9/l6MzuYxnMB/5bGowT5fuo8kTbRHq5IGLcBg4AXrHGXs4bGV/n+EfgCsBh4gw+H3G7uXpN9Dvj+7NBbS+NZZP4E3GdmY2k8C853gJvN7BUa/23Po/GFVT8B7jGzF7L3v6qZbaw2swnAHBr3dh919wezn/4B8DDwDo2n3+uavf73wG/N7DvArkPl75vZ00B34JvZ62YC/zt72H1h9u+Ju68zs/lm9irwWPa+v2dmO4DNwP/e/7KKxENnCxKRdmFmc4HvuvuitFtE8pEOKYuIiASgPVwREZEAtIcrIiISgAauiIhIABq4IiIiAWjgioiIBKCBKyIiEoAGroiISAD/P/zgV5pKbVzYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', color='black')\n",
    "ax.set_ylabel('Actual outputs', color='black')\n",
    "ax.xaxis.set(ticks=range(10))\n",
    "ax.yaxis.set(ticks=range(10))\n",
    "ax.set_ylim(9.5, -0.5)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       0.89      0.91      0.90        35\n",
      "           2       0.94      0.92      0.93        36\n",
      "           3       0.88      0.97      0.92        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.97      0.97      0.97        40\n",
      "           6       0.98      0.98      0.98        44\n",
      "           7       0.91      1.00      0.95        39\n",
      "           8       0.94      0.85      0.89        39\n",
      "           9       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.94      0.94       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dac4372839ee31ea8922f5c01c9ab80fd5aa575c72c1f76bbc3ccff5d54b2c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
